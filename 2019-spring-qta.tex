\documentclass[abstract=on,parskip=full,headings=standardclasses,fontsize=11pt,paper=a4]{scrartcl}
\usepackage[paper=a4paper,left=21mm,right=21mm,top=20mm,bottom=25mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

\usepackage{adjustbox}
%\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{fullpage}
\usepackage{authblk}
\usepackage{setspace}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{url}
\urlstyle{sf}
\usepackage{lmodern}
\usepackage[parfill]{parskip}
%\usepackage{url}
%\urlstyle{same}
\usepackage[small]{titlesec}
\usepackage{marvosym}

\setcounter{secnumdepth}{0}

\addto\captionsenglish{% Replace "english" with the language you use
  \renewcommand{\contentsname}%
    {Course Structure}%
}


\input{mueller_bib_custom.tex}

\bibliography{/Users/smueller/Documents/GitHub/literature/muellerlibrary.bib}
%\bibliography{/Users/stefan/GitHub/literature/muellerlibrary.bib}


\usepackage{xcolor}
\definecolor{JournalBlue}{RGB}{0, 12, 146}
%https://en.wikibooks.org/wiki/LaTeX/Colors
\usepackage[colorlinks=true, linkcolor=JournalBlue, filecolor=black, urlcolor=JournalBlue, pdfborder={0 0 0},citecolor=JournalBlue]{hyperref}%RoyalBlue
%\usepackage[colorlinks]{hyperref}

\clubpenalty = 10000 
\widowpenalty = 10000 
\displaywidowpenalty = 10000

\setlength\parindent{0pt}


\usepackage{titlesec}
\titleformat{\section}
   {\normalfont\Large\bfseries}{\thesection}{1em}{}
   
   

\begin{document}
	
\singlespacing

\noindent
\adjustbox{valign=t}{\begin{minipage}{0.38\textwidth}% adapt widths of minipages to your needs
\includegraphics[width=\linewidth]{pictures/uzh_logo_en}
\end{minipage}}%
\hfill%
\adjustbox{valign=t}{\begin{minipage}{0.62\textwidth}\raggedleft
{%\footnotesize
\textbf{Stefan Müller} \\
Researcher \\
Chair of Policy Analysis \\
University of Zurich \\
%\Letter\ \href{mailto:mullers@tcd.ie}{\textsf{mullers@tcd.ie}} \\
\url{https://muellerstefan.net} \\
}
\end{minipage}}

\singlespacing
\vspace{1cm}

\begin{center}
{\large Seminar \href{https://studentservices.uzh.ch/uzh/anonym/vvz/index.html#/details/2018/004/SM/50926554}{615786}} \\ 
\medskip
{\Large \textbf{Quantitative Text Analysis}} 
\bigskip

%{\large  \textcolor{red}{Draft (last update: \today)}}

{\large  {Draft (last update: \today)}}\\
\bigskip

Latest version: \url{https://muellerstefan.net/teaching/2019-spring-qta.pdf}
\end{center}

\vspace{1.5cm}

\hrule
\medskip
% first column
\begin{minipage}[t]{0.5\textwidth}
Term: Spring term 2019 \\
Time: Monday, 12:15--13:45 \\
Lecture Room: \textbf{NA} \\
ECTS: 6.0
\end{minipage}
%second column
\begin{minipage}[t]{0.5\textwidth}
\begin{flushright}
Lecturer: Stefan Müller \\
Office:  AFL H 349\\
Office hours: \textbf{NA} \\
E-Mail: \textsf{\href{mailto:mueller@ipz.uzh.ch}{mueller@ipz.uzh.ch}}
\end{flushright}
\end{minipage}
\medskip
\vspace{2.5mm}
\hrule 

\section*{Course Content}

In recent times the availability of textual data has increased massively, and there are multiple opportunities for analysing these data to answer social science research questions. This course introduces students of political science to the quantitative analysis of textual data. We cover a treatment of underlying theoretical assumptions, applications of these methods in the scholarly literature, and the respective implementations in the \textsf{R} statistical programming language.

Each session  contains practical, hands-on exercises to apply the methods to real texts. Most of these methods can be reduced to a three-step process: first, identifying texts and units of texts for analysis; second, extract quantitatively measured features from these texts and converting them to a quantitative feature matrix; third, analyse this matrix with statistical methods, such as dictionary construction and application, scaling models, and topic models, to draw inferences about the texts. Students will learn how how to apply these steps to various types of texts. There will be two homeworks which cover the theoretical assumptions as well as modelling and coding of text data. Moreover, students will use their own text corpus (or one of various text corpora provided for this course) to answer a substantive question from their personal research interests for a final project.


\section*{Details}

\begin{itemize}
\item MA/PhD seminar
\item  Language: English
\item Grading: 2 Homeworks (20\% each); Research Paper (60\%)
\end{itemize}

\section*{Learning Outcomes}

At the completion of this course, students will be able to:
\begin{enumerate}
\item Understand fundamental issues in (quantitative) text analysis such as inter-coder agreement, reliability, validation, accuracy, and precision.
\item Convert texts into quantitative matrices of features, and then analyse those features using statistical methods.
\item Use human coding and annotations of texts to train supervised classifiers.
\item  Apply these methods to a custom text corpus in order to tackle a substantive research question.
\end{enumerate}


\section*{Introductory Readings}

\subsection*{General Readings}

The seminar does not build on a single text book, but relies mostly on papers and chapters of books. For  a general overview of quantitative text analysis, natural language processing, and computational social science, the following books are recommended.

\begin{itemize}
\item \fullcite{jurafsky}.
\item \fullcite{manning08}.
\item \fullcite{salganik18}.
\end{itemize}


\subsection*{Technical Background}

The following books and websites are helpful to refresh and extend the knowledge of  \textsf{R}, RMarkdown, and the \texttt{quanteda} package.  Websites such as \href{https://stackoverflow.com/}{Stack OverFlow}, \href{https://www.r-bloggers.com}{R bloggers}, and the documentation of \textsf{R} packages will be useful for solving practical problems. The books below are published in print, but also legally available online.

\subsubsection*{\textsf{R}, RMarkdown, and \texttt{quanteda}}
\begin{itemize}
\item \fullcite{wickham17}.
\item \fullcite{xie18}.
\item \fullcite{watanabemueller}.
\end{itemize}

\subsubsection*{Data Visualisation}

\begin{itemize}
\item \fullcite{healy19}.
\item \fullcite{wilke19}.
\end{itemize}

\section*{Software and Packages}

The applications of the course are based on the \textsf{R} statistical programming language. Participants should download and install the latest versions of \textsf{\href{https://www.r-project.org}{R}} and \href{https://www.rstudio.com/products/rstudio/}{RStudio}. Students should also install the latest releases of the following  \textsf{R} packages, which will be used throughout the course.

\begin{itemize}
\item Quantitative text analysis: \href{https://quanteda.io/}{\texttt{quanteda}}
\item Importing text data: \href{https://readtext.quanteda.io/}{\texttt{readtext}}
\item Topic models: \href{https://cran.r-project.org/web/packages/topicmodels/index.html}{\texttt{topicmodels}}  and \href{https://www.structuraltopicmodel.com/}{\texttt{stm}}
\item Data wrangling and visualisation: \href{https://www.tidyverse.org}{\texttt{tidyverse}} (esp. \href{https://dplyr.tidyverse.org}{\texttt{dplyr}}, \href{https://tidyr.tidyverse.org}{\texttt{tidyr}}, \href{https://lubridate.tidyverse.org}{\texttt{lubridate}}, and \href{https://ggplot2.tidyverse.org}{\texttt{ggplot2}})
\item Creating documents and reports: \href{https://rmarkdown.rstudio.com}{\texttt{rmarkdown}} and \href{https://yihui.name/knitr/}{\texttt{knitr}}
\item Part-of-speech tagging and lemmatisation: \href{https://spacyr.quanteda.io}{\texttt{spacyr}} (installation not mandatory)
\end{itemize}

Additionally, I strongly encourage students to get used to \href{https://git-scm.com}{\texttt{git}}  and set up a \href{https://github.com}{GitHub} account (recently, GitHub started to provide unlimited private repositories even in their free version). The free  and open-source software \href{https://desktop.github.com}{GitHub Desktop} allows to use git and GitHub without having to rely on the terminal. The following sites contain comprehensible introductions to \texttt{git} and GitHub:
\begin{itemize}
\item \url{https://guides.github.com/activities/hello-world/}
\item \url{https://happygitwithr.com}
\end{itemize}


\section*{Syllabus Modification Rights}

I reserve the right to reasonably alter the elements of the syllabus at any time. More often than not this will mean adjusting the reading list to keep pace with the course schedule, although I may change the content of specific sessions depending on the prior knowledge and interests of the course participants.


\section*{Expectations and Grading}


\begin{itemize}
\item Students are expected to read all papers or chapters assigned under \textbf{Readings}. These readings serve as the basis for in-class discussions about the advantages, disadvantages, and applicability of the various approaches to social science questions. For each session, I also assign a variety of optional readings which are not mandatory, but I strongly encourage students to (at least) skim these reading. Both the required  and the optional readings consist of technical  readings and at least one practical application of the respective method.
%\item Students submit two \textbf{Homeworks}, each of which counts towards  20\% of the final grade. The homeworks will be distributed via \href{https://www.id.uzh.ch/de/dl/elearning/services/olatunizh.html}{OLAT} 14 days before the submission deadline as an RMarkdown file. Students fill in the answers and solutions in the same RMarkdown file, rename it  to \texttt{hw\_01/02\_surname\_firstname.Rmd}, knit it as an \texttt{html} file, and submit it via OLAT. Only knitted \texttt{html} files will be accepted. The deadline for Homework 1 is \textbf{March 22, 2019 (8:00pm CET)}, the deadline for Homework 2 is \textbf{April 26, 2019 (8:00pm CET)}. More details on the homeworks will be provided in the first session(s) of the course. 
\item Students also submit a \textbf{Research Paper} which counts towards 60\% of the final grade. The research paper is a written analysis of 5,000--5,500 words (including bibliography, captions, and footnotes). Students are required to develop a research design to answer a question with textual data. Students are free to answer questions from all subfields of political science, but must justify their choice and the relevance of the question.  Students registered for an MA degree in another social science discipline are encouraged to develop a research project answering a question from their subject.   Students can use existing corpora, create their own text corpus, or access textual data that may be collected in spring at the Computational Social Science Hub (part of the \href{https://digdemlab.github.io}{Digital Democracy Lab}).  The research papers must be submitted via OLAT as a \texttt{pdf} document before \textbf{June 14, 2019 (8:00pm CET)}.  In the 10th and 11th session, each student gives a  short  presentation, covering the research question, relevance, text corpus, and methodological approach. Alongside with the presentation,  students will submit a 1,000 words research proposal to receive comments from peers and the lecturer. Each project will be discussed through \textit{written} feedback by another seminar participant, and students will also receive written feedback from me. Detailed instructions on the research paper, the presentation, and the in-class discussion will be provided via OLAT.
\end{itemize}



\begin{table}[h] \centering \onehalfspacing
\caption*{Overview of deadlines}
\begin{tabular}{ l l l} 
\toprule
Date &  Time & Assignment \\
\midrule
Friday, March 22, 2019 & 8:00pm CET &  Homework 1 (20\%)  \\
Friday, April 26, 2019 & 8:00pm CET  & Homework 2 (20\%) \\
Friday, June 14, 2019 & 8:00pm CET & Research Paper  (60\%) \\
\bottomrule
\end{tabular}
\end{table}



\tableofcontents

\newpage

\section{Week 1: Organisation and Introduction (February 18)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are quantitative text analysis and natural language processing?
\item What is the structure of the course and what are the expectations?
\item \textit{Application}: installing packages and setting up a Project in RStudio
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{grimmer13}.
\item \fullcite{dimaggio15}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{lazer17}.
\item \fullcite{hirschberg15}.
\item \fullcite{gentzkow17}.
\end{itemize}


\section{Week 2: Assumptions and  Workflow (February 25)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are the underlying assumptions of text-as-data approaches?
\item \textit{Application}: importing textual data, creating a text corpus, and adding document-level variables
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{benoit18}.
\item \fullcite{wilkerson17}.
\end{itemize}


\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{gilardi19}.
\item \fullcite{monroe15}.
\end{itemize}

\section{Week 3:  Tokenisation and Document-Feature Matrix (March 4)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are tokens, types, and features? What is the difference between stemming and lemmatisation?
\item \textit{Application}: tokenising texts, and creating a document-feature matrix
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
 \item \fullcite{welbers17}.
 \item \fullcite{denny18}.
 \item \fullcite[Chapter 3]{watanabemueller}.
% \item \fullcite[Chapter 2 (Regular Expressions, Text Normalization, Edit Distance)]{jurafsky}.
\end{itemize}
 
  
\section{Week 4: Dictionaries and Sentiment Analysis (March 11)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are automated dictionary approaches? How can we create, test, and refine dictionaries?
\item \textit{Application}: creating multiword expressions and applying dictionaries to tokens objects and document-feature matrices
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{laver00}.
\item \fullcite{rooduijn11}.
\item \fullcite{soroka12}.
\item \fullcite{soroka18}.
\item \fullcite{proksch19}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{stine19}.
\item \fullcite{rudkowsky18}.
\item \fullcite{tausczik10}.
%\item \fullcite{gonzalezbailon15}.
\item \fullcite{muddiman19}.
\item \fullcite{rauh18}.
% \item \fullcite[Chapter 19 (Lexicons for Sentiment, Affect, and Connotation)]{jurafsky}.
\end{itemize}

\section{Week 5: Textual Statistics, Text Similarity and Reuse (March 18)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item How do texts differ in their `readability' and complexity? What are measures to estimate the similarity and distance between texts?
\item \textit{Application}: creating n-grams; estimating complexity and similarities/distances of texts
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{wilkerson15}.
\item \fullcite{cross17}.
\item \fullcite{bischof18}.
\item \fullcite{benoit19}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{allee16}.
\item \fullcite{linder18}.
\end{itemize}


\section{Week 6: Human Coding and Document Classification (March 25)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item How can we classify documents into known and pre-defined categories? What is crowd-sourced coding?
\item \textit{Application}: typical workflow of human coding using crowdsourcing; Naïve Bayes classification
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{mikhaylov12}.
\item \fullcite{benoit16}.
\item \fullcite[Chapter 4 (Naïve Bayes)]{jurafsky}.
\item \fullcite{peterson18}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite[Chapter 13 (Naïve Bayes)]{manning08}.
\item \fullcite{benoit09}.
\item \fullcite{king17}.
\item \fullcite{hopkins10}.
\item \fullcite{watanabe18}.
%\item \fullcite{horn18}.
\item \fullcite{diazlopez17}.
%\item \fullcite{loftis18}.
\end{itemize}

 
\section{Week 7:  Supervised Scaling (April 1)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are the assumptions, advantages, and problems of supervised scaling?
\item \textit{Application}: Worscores
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{laver03}.
\item \fullcite{laver14}.
\item \fullcite{baturo17}.
\item \fullcite{herzog15}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{lowe08}.
\item \fullcite{martin08b}.
\item \fullcite{perry17}.
\end{itemize}


\section{Week 8: Unsupervised Scaling (April 15)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item What are differences between supervised and unsupervised scaling methods? How can we validate scaling models?
\item \textit{Application}: Wordfish and Wordshoal
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{slapin08}.
\item \fullcite{lowe13}.
\item \fullcite{schwarz17}.
\item \fullcite{kluever09}.
\end{itemize}

\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{lauderdale16}.
\item \fullcite{catalinac18}.
\item \fullcite{greene16b}.
\item \fullcite{baerg20}.
\item \fullcite{storz18}.
\end{itemize}


\section{Week 9: Topic Models (April 29)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item How does unsupervised document classification work? What are the assumptions, advantages, and caveats of topic models? 
\item \textit{Application}: Latent Dirichlet allocation (LDA) and structural topic models (STM)
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{blei03}.
\item \fullcite{blei12}.
\item \fullcite{roberts14}.
\end{itemize}


\subsubsection*{Optional}
\begin{itemize}
\item \fullcite{grimmer10}.
\item \fullcite{boussalis16}.
\item \fullcite{catalinac16}.
\item \fullcite{jacobi16}.
\item \fullcite{gilardi18}.
\end{itemize}

\section{Week 10: Presentation of Projects [I] (May 6)}

In this session, the first half of students will present their projects. The remaining projects will be presented in the following session. Detailed instructions on the presentations, the written outline of the research design, and how to discuss each other's proposal will be distributed through OLAT.


\section{Week 11: Presentation of Projects [II] (May 13)}

In this session, the second half of students will present their projects. 



\section{Week 12: Social Media and Multilingual Analysis (May 20)}

\begin{itemize}
\renewcommand\labelitemi{--}
\item How can we analyse social media posts with text-as-data approaches? In what ways can we conduct multilingual analyses? 
\item \textit{Application}: scraping Twitter data using an API; introducing platforms for machine translation
\end{itemize}

\subsubsection*{Readings: Social Media}
\begin{itemize}
\item \fullcite{mitts19}.
\item \fullcite{pfeffer18}.
\end{itemize}

\subsubsection*{Readings: Machine Translation}
\begin{itemize}
\item \fullcite{evans16}.
\item \fullcite{lucas15}.
\item \fullcite{devries18}.
\end{itemize}


\section{Week 13: New Directions and Applications (May 27)}


\begin{itemize}
\renewcommand\labelitemi{--}
\item What are future directions in natural language processing?
\item \textit{Application}: introducing assumptions of word2vec and deep learning approaches
\end{itemize}

\subsubsection*{Readings}
\begin{itemize}
\item \fullcite{king13}.
\item \fullcite{lecun15}.
\item \fullcite{mikolov13}.
\item \fullcite{mueller18b}.
\item \fullcite{joo}.
\end{itemize}

\subsubsection*{Optional}

\begin{itemize}
\item \fullcite{chollet18}.
\item \fullcite{salganik18}.
\end{itemize}


%\newpage
\sloppy
\renewcommand*{\bibfont}{\small}

\setlength{\bibitemsep}{0.2em} % increase space between references
\printbibliography

\bigskip

%\begin{center}
%Last updated: \today
%\end{center}

\end{document}


